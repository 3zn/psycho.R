---
title: "Extracting a Reference Grid of your Data for Machine Learning Models Visualization"
layout: post
output:
  html_document:
    df_print: paged
    toc: yes
  md_document:
    toc: yes
    variant: markdown_github
author: "Dominique Makowski"
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---


```{r message=FALSE, warning=FALSE, include=FALSE}
library(knitr)
set.seed(666)
```

Sometimes, for visualization purposes, we want to extract a reference grid of our dataset. This reference grid often contains equally spaced values of a "target" variable, and all other variables "fixed" by their mean, median or reference level. The `refdata` of the [`psycho` package](https://github.com/neuropsychology/psycho.R) was built to do just that.

# The Model

Let's build a complex machine learning model (a neural network) predicting the Sex of our participant with all the variables of the dataframe.

```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='hide', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
# devtools::install_github("neuropsychology/psycho.R")  # Install the latest psycho version if needed

# Load packages
library(tidyverse)
library(caret)
library(psycho)

# Import data
df <- psycho::affective %>% 
  standardize() %>%  # Standardize
  na.omit(df)  # Remove missing values

# Fit the model
model <- caret::train(Sex ~ .,
                      data=df,
                      method = "nnet")
```
```{r message=FALSE, warning=FALSE}
varImp(model, scale = TRUE)
```

It seems that the upper salary category is the most important variable of the model, followed by the concealing and adjusting personality traits. Interesting, but what does it say about the actual relationship between those variables and our outcome?


# Simple

To visualize the effect of Salary, we can extract a reference data with all the salary levels and all other variables fixed at their mean level.

```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='hide', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
newdata <- df %>% 
  select(-Sex) %>% 
  refdata("Salary")
newdata
```
```{r message=FALSE, warning=FALSE}
knitr::kable(newdata, digits=2)
```

We can make predictions from the model on this minimal dataset and visualize it.

```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='hide', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
predicted <- predict(model, newdata, type = "prob")
newdata <- cbind(newdata, predicted)

newdata %>% 
  ggplot(aes(x=Salary, y=M, group=1)) +
  geom_line() +
  theme_classic() +
  ylab("Probability of being a man")
```

Well it seems that males are more represented in categories in lower and uppper salary classes.

# Multiple Targets

How does this interact with the concealing personality trait?

```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='hide', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
newdata <- df %>% 
  select(-Sex) %>% 
  refdata(c("Salary", "Concealing"))  # We can sepcify multiple targets

predicted <- predict(model, newdata, type = "prob")
newdata <- cbind(newdata, predicted)

newdata %>% 
  ggplot(aes(x=Concealing, y=M, colour=Salary)) +
  geom_line() +
  theme_classic() +
  ylab("Probability of being a man")

```

This plot is rather ugly...

# Increase Length

```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='hide', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
newdata <- df %>% 
  select(-Sex) %>% 
  refdata(c("Salary", "Concealing"), length.out=500)  # Set the length by which to spread numeric targets

predicted <- predict(model, newdata, type = "prob")
newdata <- cbind(newdata, predicted)

newdata %>% 
  ggplot(aes(x=Concealing, y=M, colour=Salary)) +
  geom_line(size=1) +
  theme_classic() +
  ylab("Probability of being a man")
```

It seems that for richer people, the concealing treshold for increasing the probability of being a male is lower. 


# How to Fix Numeric Variables?

Note that here, all other variables are fixed to mean. But maybe this behaviour would be different when other variables are low or high.

```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='hide', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
newdata_min <- df %>% 
  select(-Sex) %>% 
  refdata(c("Salary", "Concealing"), length.out=500, numerics = "min") %>%  # Set the other numeric variables to their minimum 
  mutate(Fixed = "Minimum")
newdata_max <- df %>% 
  select(-Sex) %>% 
  refdata(c("Salary", "Concealing"), length.out=500, numerics = "max")%>%  # Set the other numeric variables to their maximum 
  mutate(Fixed = "Maximum")
newdata <- rbind(newdata_min, newdata_max)

predicted <- predict(model, newdata, type = "prob")
newdata <- cbind(newdata, predicted)

newdata %>% 
  ggplot(aes(x=Concealing, y=M, colour=Salary)) +
  geom_line(size=1) +
  theme_classic() +
  ylab("Probability of being a man") +
  facet_wrap(~Fixed)
```

When all variables are set to their maximum, concealing is not related to the sex. When the variables are set to their minimum, the concealing treshold for the two lower salary classes is higher (around 1.5).


# Chains of refdata

Let's say we want one target of length 500 and another to length 5. To do it, we can nicely chain `refdata`.

```{r, fig.width=7, fig.height=4.5, eval = TRUE, results='hide', fig.align='center', comment=NA, message=FALSE, warning=FALSE}
newdata <- df %>% 
  select(-Sex) %>% 
  refdata(c("Adjusting", "Concealing"), length.out=500) %>% 
  refdata("Adjusting", length.out=5, numerics = "combination")

predicted <- predict(model, newdata, type = "prob")
newdata <- cbind(newdata, predicted)

newdata %>% 
  mutate(Adjusting=as.factor(Adjusting)) %>% 
  ggplot(aes(x=Concealing, y=M, alpha=Adjusting)) +
  geom_line(size=1) +
  theme_classic() +
  ylab("Probability of being a man")
```


# Credits

This package helped you? Don't forget to cite the various packages you used :)

You can cite `psycho` as follows:

- Makowski, (2018). *The psycho Package: an Efficient and Publishing-Oriented Workflow for Psychological Science*. Journal of Open Source Software, 3(22), 470. https://doi.org/10.21105/joss.00470
